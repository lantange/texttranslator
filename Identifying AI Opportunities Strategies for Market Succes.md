1
00:00:10,120 --> 00:59:22,960
I'm excited to introduce our speaker, Aditya. Before we get into the webinar, I wanted to say a little bit about Aditya. Aditya Chapali is a Machine Learning Engineer and Product Lead. He currently works at Microsoft, where he helps build generative AI products that are used by millions globally. He's also an adviser to several Silicon Valley startups and Fortune 500 companies. Aditya lectures on product management and AI both at Stanford School of Engineering and Center for Professional Development. Aditya is here as part of a new course that just launched on July 29th, and if you want to learn more about the course, there are links listed here within the platform. So, without further ado, I'm going to turn it over to Aditya to start our webinar.

Awesome, thank you very much, Jess. I'm super excited to be here. The title for today's webinar is "Identifying AI Opportunities: A Strategy for Market Success," but really what I want to do is bust a lot of myths that people seem to have about AI and generative AI. One of the most common sets of questions that we get around generative AI is: How do I personally succeed in generative AI? How do I get in, and if I'm in there, how do I succeed as a business or technical professional? We've done a lot of research on that topic as well, so I'm super excited to share those insights with you. Obviously, there's a Q&A section where you can post questions, and we'll stop very regularly to address some of those questions. We'll also have points throughout this presentation where I'll ask you questions to understand if you are following the process so far.

Okay, so a little bit about the information in this webinar: It's taken from the course that Jess mentioned that my colleagues and I teach at Stanford Professional. To gather the information for this course, we spoke to over 50 executives, conducted a user research survey with over 300 users, and we've put a lot of thought into making sure that these answers are correct, valid, and backed by substantial data. So let's dive into it.

One of the first things I want to talk about is this curve where I want to discuss a phenomenon with you specifically. You can post your guesses in the chat about what you think this phenomenon might be. This is the internet curve. Initially, people thought it was a bubble where they said, "Is it a bubble or is it going to create real value?" There was a lot of discussion. Then people started saying, "Oh, we have other priorities, we've built an internal tool to compensate or to deal with this work." Then people said, "Oh, companies started getting disrupted, new ones started getting created." And now we're here in this new process.

Exactly, this is generative AI. Generative AI is following the exact same curve process as the internet, literally bit by bit. People initially thought it was a bubble, and then they had some discussion around it. Now we're past that with generative AI; we know it's clearly going to create a lot of value. But a lot of companies now are dealing with it by just building internal tools and not necessarily building user-facing products. Those people are losing, just like those who did that with the internet have lost essentially. The people who took advantage of it disrupted those previous companies.

What's more astounding is that the internet went on to create a thousand times more value than people estimated in 1999. So at the peak of the bubble, people thought that was as big as it was going to get, and now, almost 25 years later, we have created a thousand times more value than that. We expect that same curve to happen with generative AI, so we can use a lot of those same lessons.

Specifically, we're still in the early days of generative AI. Because it's a new platform, nobody knows who's going to win, and the tech is improving extremely rapidly such that users themselves don't even have solid preferences yet. The information we're going to share is based on very early research, but we have a strong sense that it's correct. However, it's still evolving rapidly.

The most exciting part about all this is that the game is yours to capture. I would almost say we're going to tell you some secrets in this webinar because this data has been, let's say, locked up for people in our course or executive workshops that we've done, and now we're releasing it. People have used these insights to create millions of dollars of value, so we're super excited to share that with you today.

Now, let's dive into the actual tech behind generative AI. At this point, people are very familiar with what generative AI can do in general, but there are still a few things people get wrong. Number one, note that "generative AI" is a marketing term; it's not an actual technical term. Generative AI actually refers to various different types of models like generative adversarial networks, transformer models, or variational autoencoders.

If you're a non-technical person, like a business professional, don't go around saying you work in "gen AI." We see this happen all the time with business professionals especially. Nobody calls themselves a "gen AI engineer"; they call themselves an ML engineer or a machine learning engineer. So you shouldn't call yourself a "gen AI business professional" necessarily. You should be calling yourself a machine learning professional or some sort of technical professional in some sense, or an ML business professional. Definitely not a "generative AI business professional" unless you're doing it for marketing purposes. If you're going to an engineering team, just don't use the word "gen AI" - use "machine learning."

There are various types of generative AI applications, and I will be using the terms "gen AI" going forward because obviously we all understand what it means. The first type is a collaborative type of generative AI application, where every idea is amplified and every possibility is explored while you work. The second is personalized generative AI, where everything is created for you, so everything will become a market of one. And then there's proactive generative AI, which takes action for you.

These are the three types, and the reason for this classification is that if you project all of these going forward, you can see a world where generative AI surrounds you in everything you do. For example, when you open up TikTok or Instagram in the future, all these creators could potentially be generative AI. In collaborative scenarios, you could potentially have many team members working with you that could all be generative AI assistants. And for proactive tasks, if you have to go out and do a list of chores, that could all be done for you by AI.

There's a bunch of enabling technologies behind this, like text, image, audio, and video generation, which we won't dive into deeply. Just know that when people talk about generative AI now, they often think about writing chatbots or similar applications, but the most significant advancements are likely 5-10 years ahead of us.

Now, let's talk about the first paradigm shift associated with generative AI tech. Previously, you needed a lot of data, infrastructure, and algorithms to build your own model. This is something like Facebook or TikTok - they had all these data centers and data scientists to make amazing recommendation algorithms. Now, those models come fully functional out of the box. People don't realize how drastic of a change this is. Not only is generative AI really amazing and smart, but companies like OpenAI have actually made it public for everybody. That's the equivalent of Facebook saying, "You can use our recommendation algorithm; just give us your content and we'll rank it for you." And that's amazing.

Because of that, we see a lot more opportunities and investment opportunities opening up. We're going to talk quickly about how to access these models, and then we're going to discuss those investment opportunities and how you can potentially make a lot of money. We'll also cover how people have used insights from this webinar to really advance their goals, either to make money or to advance in their careers.

There are primarily two ways to access these models. The first one is to call a model creator like OpenAI or DeepMind with an API. The second one is to host your own open-source model. There are plenty of open-source models, many that rival the more closed-source versions, like LLaMA. The amazing part about this is that these resources are democratized like never before. If you take one thing away from this session, it should be that most people aren't recognizing the massive paradigm shift that free intelligence is providing. This is completely free intelligence that you can host by yourself, and that opens up a ton of new investment opportunities, which we're going to talk about in a second.

Let's take a quick pause. Does anybody have any questions so far about the technical section? You can post them in the chat, and we'll wait a few seconds if you do.

Aditya, one question that did come up in general is: Do you need to know the technical details of generative AI to be a good leader?

That's an excellent question, which we're actually going to cover in depth in a few sections. Specifically, we'll discuss it in the personal section about how you can succeed as a professional in this new post-AI world.

Okay, let's talk quickly about some types of generative AI companies, and specifically, we want to talk about where the most money is and where people are going to make the most money. There are three types of major companies that take advantage of generative AI:

1. Takers: They just take the model and put a user interface in front of it. This is the best place to start.
2. Model Customizers: These are companies that take a model, add their own data into it, and then customize the model. This is the best long-term place to be.
3. Model Creators: These are companies that actually go out and create the models.

We're going to talk in a second about how everybody's wrong about where most of the money is in these cases, but first, we're going to layer these companies.

To understand where those companies make a lot of money or who's going to make a lot of money, we first have to understand the technical stack and the industry stack. At the bottom, there's compute hardware - these are companies like NVIDIA that make the chips. Then there are cloud platforms that sit on top, like Google, Amazon, and Azure. On top of those, there are people who create the models using these cloud and data services. Then there are people who take those models and make them open source, and finally, people who customize those open-source models or put them in front of users.

Now, I'm going to ask you a question, and you can post your answers in the Q&A: If you had $1 million to invest, which company would you choose? Mistral AI, which is a model creator that has recently raised a lot of money and made cutting-edge models, or Thomson Reuters' Westlaw, a legal database that holds information about legal cases, their outcomes, and associated information?

We'll wait a few minutes to get people's answers in the chat.

It seems like most people are saying Mistral AI, but that's actually incorrect. The myth is that model creators will make all of the money, and that's wrong. In fact, the reality is that models are becoming commoditized, and these model creators are actually competing against each other. They're not struggling to make money, but there's not a lot of money to be made there.

In fact, we're going to talk about how this democratization is making it such that these generative AI models are providing really accessible foundation models to app developers. This allows these app developers to unlock 10 times more businesses without running any significant investment in their own data science centers.

Now, let's talk about how this affects the profit of each layer in the generative AI ecosystem:

1. Compute Hardware: Companies like NVIDIA are super defensible and they're going to make a ton of money.
2. Cloud Platforms: They will probably provide the same sort of profitability profiles as they've previously provided with cloud services, so generally quite high but not insane compared to model app users.
3. Model App Users: These takers and customizers we were talking about earlier are actually making the most amount of money.

Let's spend a few moments explaining why. The biggest myth is that these "wrappers" - apps that take ChatGPT and large language models and put a user interface in front of them - don't make a lot of money. An example of this could be Perplexity or various ones like Julius that customize ChatGPT for data scientists or researchers. In fact, these apps are making a ton of money.

Here's why: ChatGPT or these large language models are only used regularly by about 100 million people a month. That means there are still 7.9 billion people in the world who don't use ChatGPT or these LLMs regularly. Making ChatGPT or these LLMs accessible to those 7.9 billion people is an extremely lucrative opportunity, and that's what these wrappers are doing.

People have pointed out that data is the real oil. We're going to talk about in a second how that's not entirely true. Data is quite significant, but what's even better is another type of competitive advantage that large companies have.

Now, I'm going to ask you a question: What is the biggest moat in generative AI? Is it:

a) A newer or better model (which includes taking a model and making it better with customized data)
b) Having more GPUs
c) Having better user experience
d) Having better distribution (which means accessing a large number of users at once)

Post your answers quickly in the chat, and then we'll discuss who's right.

The split seems to be mostly between user experience and distribution, with some people answering other options. The people who said distribution are correct. Congratulations to those folks!

Here's why: People talk about data being the new oil. That used to be true when you had to make your own ML models and AI models. It was necessary to have a lot of data because you essentially constructed these models from scratch. But now that's not true anymore. You don't necessarily need better models or better data because these models are so good out of the box.

User experience is really valuable - if I had to give the second-best answer here, it would be user experience. But it's still not the best because even if you have a subpar user experience, if you have access to a large number of users, that's actually fine. Our research has found that people will accept even a slightly worse user experience if the results help them. It doesn't really matter if the user experience is amazing as long as the results are somewhat helpful, and that's what distribution offers here.

Distribution is really the key to winning here, and we're going to talk about how that affects the types of companies that are going to win. When people think about making these generative AI products, whether you're a startup or a large company, the game has changed. Previously, the way to win would be to gain the best model or data, or make an amazing user experience that people always come back to. Now, the game is about how to get this into the hands of everybody as quickly as possible in this new market of 7.9 billion people who aren't using these tools regularly.

Let's bust some myths versus reality:

Previously, the biggest advantages used to be talent, infrastructure, and model quality that big tech companies had because you needed that to make your own model. Now, the biggest advantages are:
1. Distribution
2. User experience
3. Data

What this means is that the moats have been flipped completely with generative AI. Now the strongest moat is distribution, and the weakest moat is the algorithm. The paradigm shift is that you previously needed a lot of money, a lot of models, and thousands of employees to win. Now, all you need is really good UI/UX, some unique data, and 10 employees. These three things will enable you to get good distribution.

Let's look at a comparison: Between IBM and JP Morgan, if you had to guess which company was better positioned to succeed in generative AI, it would be JP Morgan. This is interesting because IBM has a lot of talent, money, and GPUs. But JP Morgan has wider distribution to more end users, and then it can potentially build a flywheel with the data and user experience in that iterative model.

Most of the market doesn't understand this. Whenever IBM makes a generative AI announcement, their stock goes up. But in fact, it should be JP Morgan's stock that's going up. If anything, JP Morgan's stock or its equivalents are undervalued compared to their potential for generative AI. (Note: This is not investment advice; I'm just pointing out a common misconception.)

To recap: The key AI winners used to be big tech companies because they had a lot of money, models, and specialized employees. Now, the key generative AI winners are actually non-tech companies, and they themselves often don't realize this. The mistake they make is that they keep building internal tools and things that don't really take advantage of this new world.

If you're part of those companies, you should start realizing that you are actually better positioned to succeed than these tech companies. The real value is in integrating AI to enhance existing systems because you already have a lot of distribution and you can pump generative AI experiences through those. You have a lot of data and a large user base.

Let's look at one last example. Of these four companies, which do you think is best positioned to succeed in generative AI?

1. Chat-base: Takes ChatGPT and puts it on a website
2. Cohere: Makes amazing models for the enterprise world
3. Riz GPT: Allows you to improve how you talk to other people (for dating or general conversation)
4. Perplexity: Allows you to search and get better results with generative AI

The only wrong answer is Cohere. The rest are all well-positioned to succeed because they have the ability to put really good user experiences in front of these models and are getting a lot of distribution. Cohere, on the other hand, is actually laying off employees and cutting back deals, showing some of the cracks in the model creation business.

To give you an idea of their success: Riz GPT got sold for millions of dollars, Chat-base is making millions in ARR (Annual Recurring Revenue), and Perplexity has about 100 million users.

Now, let's move on to some personal tips. This is a bit of a jump because so far we've talked about where companies succeed and where the most money is, but I want to take a bit of an aside. The most common question we get from professionals is: "How do I succeed? What do I need to do?" We especially get this from non-technical professionals, more business-oriented professionals. So I want to talk through how we've seen people succeed.

The curriculum we're going to put out has helped people increase their compensation or their success significantly. I can speak to one person who more than doubled their income to $500,000 because they took this curriculum quite seriously. So let's dive in.

The first change is that non-technical people used to not be able to build because you had to learn how to code and do all the system architecture. Now, non-technical people can build, and I'll explain why. There are different stages from beginner to advanced level of building, but let me explain how your job as a non-technical person can change.

Previously, let's say you're a PM (Product Manager), and you don't necessarily have to be a PM - you could be any sort of business professional. You can start to act as a data scientist way more than before. Now, what a data scientist or an applied scientist does is they don't make new models. What they do is:

1. They give ChatGPT or these LLMs new data and ask it to be fine-tuned.
2. They tune prompts, basically fiddling with the English language to make sure that they get the results that they want.

It's a reasonably easy skill to contribute, and if you pick it up, you can start going to these engineering teams or technical teams or start doing it yourself. You can say, "Hey, I want to build this app. I have this idea, and look, ChatGPT does it super well."

Let me give you an example: We worked with a bank where a banker in some regional branch put in a customer's information for a loan approval into ChatGPT (it was a company-approved instance). ChatGPT provided a great answer as to why this person should get the approval. They took that version and provided the approval to the customer for the loan, basically using ChatGPT for the rationale. It was so helpful that the company approved this use case for everybody to use, and now this banker is actually leading this initiative across the bank on launching generative AI. Their career went from being a regional representative to now leading this company-wide technical initiative, all because they were just fiddling with prompts.

There's such a demand from these companies that even some small efforts are really appreciated. We talk to leaders all the time who say, "Our employees don't do enough of this, and we want to see more."

Another thing is, if you're a business professional, one of the things you used to have to do is ask, "Is this even feasible? If I want to build an app, how long would it take? How many engineers would we need?" You had to consider all of those estimates. Now, you don't need to do any of that. You can go to ChatGPT and get the answer yourself. You can just say, "Hey, can you do this? If so, what do you need?" and it provides the answer for you.

We'll talk about this in a little bit more technical detail in a few slides, but if you're in a tech-adjacent role, how you communicate business requirements completely changes now. You can come in with examples of prompts and output content. You can be the leader in how generative AI limits or expands your scenario. You can say, "Hey, you know what? I can be the leader in my organization for what generative AI can or can't do and how feasible it is to get it to do a certain piece of the app." Then you're going to research data and privacy requirements beforehand.

We're going to talk about it in a few seconds how more specifically you can do these things to advance your career.

So, what can a PM (or any business professional) do? We went out and asked 50 executives and product leaders about how, in this new world, a product manager or a business professional can expand their respect and legitimacy and grow within the organization. Here are the key points they mentioned:

1. Understand the tech in depth (we'll talk about what they mean by that and how much tech you need to understand)
2. Understand product vision
3. Can you do a PR? (PR here means Pull Request - if you can start to code even a little bit, even with prompting, that earns a lot of legitimacy)
4. Gathering and defending requirements

We did this survey three years ago and have been doing it consistently. This year, "understanding the tech in depth" was by far the biggest factor. It used to not be super important to understand the tech, but now it's extremely important. Leaders are really searching for business professionals who understand a lot more of the tech, and it's in fact the most important thing.

So, how do the best ML (Machine Learning) PMs or business professionals grow and succeed? Here's the advice:

1. Join a fast-growing company
2. Become technical
3. Become a domain expert
4. Build more side projects

Basically, there are three paths to get into generative AI: get technical, get niche domain experience, and ideally, you do both. The most common question then is, "Which one should I do? Should I go out and get domain experience like learn about a specific industry, or should I get technical?"

Most often, the advice we give for our business professionals, and the advice we see works, is to get technical. Let me spend a few minutes explaining why that is. Most business professionals already understand a little bit about their domain, a little bit about the industry. Even if you're an accountant, let's say, you understand how accounting works. You don't necessarily understand how a specific industry works, but you understand how accounting works. If you're in manufacturing, obviously you understand how manufacturing works.

What we find is that a lot of people opt for getting deeper domain expertise. When we say get deeper domain expertise here, it's still with a mix of generative AI. So you still have to say, "I know manufacturing really well, but I know manufacturing in the context of AI. So I can tell you really specifically where AI is the most helpful, what use cases have been tried before, what hasn't been tried, where has AI been successful, where has AI not been successful, and where are some prime initial customers I can get to try out some initial use cases for generative AI in a specific industry."

Because a lot of people opt for this domain expertise route, it's actually really competitive. Some people have been in this industry for 30-40 years and they know so much, they know everybody in this space. It's really hard to get competitive - you have to know an extreme level of knowledge.

On the technical side, a lot of business professionals shy away from it. They say, "I don't know how to code, I don't really understand that world." We find that if those people try to get technical and they get more technical, they sort of become unicorns because they are one of the few in the world who can bridge the gap between the technical side and the industry side.

The ideal is you have whatever 10-20 years of domain expertise and you get super technical. Then you're a unicorn. These are the types of people that we've seen make $500,000, a million dollars in a few instances, because startups and industry leaders and companies pay so much money for this advice.

Let's talk about how to get technical. There are three stages: beginner, intermediate, and advanced. If you're in this session, you're already probably past the beginner section of how to get technical, specifically related to generative AI. You just have to understand what are the rough tools, what are the rough implications, what can it roughly do at a high level, and that's pretty much it.

The intermediate and advanced levels are really where most of the money starts to come in for a lot of these people, especially at the advanced level. At an intermediate level, what we mean by how to get technical is you get extremely good at prompting, and this takes about 4-6 weeks. The basic level is understanding how to use ChatGPT at a pretty deep level. Intermediate is using system-level prompting and multi-prompt examples, really understanding how to coach it to get a set of results that are really valuable and consistent.

What you do at the advanced level is achieve consistent results with multi-channel prompting. We'll explain what that means in a second, but think of using things like JSON formatting and checker LLMs. Let me give you an example: Let's say the LLM like ChatGPT you're using doesn't give you the right result the first time. You say, "Hey, can you give me a workout regime?" and it gives you a sort of wrong workout regime. You have another LLM check the response with specific things you're looking for, like saying, "I told them I had back pain. Is it recommending squats to me? Because if so, it's a bad workout program." So you have a checker LLM set up that checks the first LLM's response.

Knowing how to use JSON formatting and structured outputs from OpenAI and all these places, and doing things like Chain of Thought (which is prompting LLMs to talk about how they get their reasoning) is crucial. We won't talk about it in more detail, but that's the advanced stage. If you really want to understand how these companies are making so much money, this is where most of it is, especially in these wrapper applications. If you learn this, you would also start to access those sorts of opportunities.

That concludes our webinar for today. Thank you all for your attention, and I hope you found this information valuable.